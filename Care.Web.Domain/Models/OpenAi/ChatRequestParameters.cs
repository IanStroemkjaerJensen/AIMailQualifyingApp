using System.Text.Json.Serialization;

namespace Care.Web.Domain.Models.OpenAi;
public class ChatRequestParameters
{
    /// <summary>
    /// Messages: A list of messages comprising the conversation so far. This includes the system message and email body to be analyzed.
    /// </summary>
    public List<Message> Messages { get; set; }

    /// <summary>
    /// Model: ID of the model to use
    /// </summary>
    public string Model { get; set; }

    /// <summary>
    /// ResponseFormat: An object specifying the format that the model must output
    /// </summary>
    [JsonPropertyName("response_format")]
    public ResponseFormat ResponseFormat { get; set; }

    /// <summary>
    /// Temperature: What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 
    /// will make it more focused and deterministic
    /// </summary>
    public float Temperature { get; set; }
    /// <summary>
    /// LogitBias: Modify the likelihood of specified tokens appearing in the completion.
    /// Accepts a JSON object that maps tokens(specified by their token ID in the tokenizer) to an associated bias value from -100 to 100. Mathematically, 
    /// the bias is added to the logits generated by the model prior to sampling.The exact effect will vary per model, but values between -1 and 1 should decrease or
    /// increase likelihood of selection; values like -100 or 100 should result in a ban or exclusive selection of the relevant token.
    /// </summary>
    [JsonPropertyName("logit_bias")]
    public Dictionary<string, int>? LogitBias { get; set; }

    /// <summary>
    /// MaxTokens: The maximum number of tokens that can be generated in the chat completion
    /// </summary>
    [JsonPropertyName("max_tokens")]
    public int? MaxTokens { get; set; }
}

public class ResponseFormat
{
    //[JsonPropertyName("type")]
    public string Type { get; set; }
}


